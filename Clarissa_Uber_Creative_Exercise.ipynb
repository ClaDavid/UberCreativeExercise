{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uber Creative Exercise - Clarissa Simoyama David"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarefa atribuída\n",
    "\n",
    "O dado que recebi como tarefa fora um arquivo de extensão PDF com meu própiro currículo. Estendendo este problema para o mundo da Uber, imaginei como deve ser feito a seleção de candidatos à motoristas para a companhia. Logo pude ver com clareza um problema que poderia ser solucionado: novos candidatos que estariam interessados a trabalharem juntos à companhia enviam seus currículos e, de alguma forma, é necessário a automatização da extração das informações do que eles enviam à empresa. Foi pensando neste problema que desenvolvi a solução que será explicada nas subseções seguintes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solução\n",
    "\n",
    "Para solucionar o problema da extração de informações de currículos em PDF, pensei em uma solução automatizada utilizando Python. \n",
    "\n",
    "A primeira etapa consiste em transformar o arquivo PDF em um arquivo TXT, para se ter uma forma mais fácil de manipulação. O script pdf2txt.py pertence à biblioteca pdfminer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pdf2txt.py Profile_\\(16\\).pdf > profile_16.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após a transformação, é feita a leitura deste arquivo para ser manipulado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_txt_to_read = open(\"profile_16.txt\", \"r\")\n",
    "profile_in_txt = file_txt_to_read.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O resultado obtido da transformação do arquivo PDF para o TXT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Contatar\\n\\nwww.linkedin.com/in/clarissa-\\ndavid-a10824170 (LinkedIn)\\ngithub.com/ClaDavid (Other)\\n\\nPrincipais competências\\nAprendizado de máquina\\nMineração de dados\\nProgramação de computadores\\n\\nLanguages\\nEspanhol (Limited Working)\\nInglês (Full Professional)\\nPortuguês brasileiro (Native or\\nBilingual)\\n\\nCertifications\\nSupercomputer with NVIDIA K20\\nboards\\nIntroduction to Object-Oriented\\nProgramming\\n\\nHonors-Awards\\nACM International Collegiate\\nProgramming Contest/XXI Maratona\\nde Programação\\nInvestigation of the use of text\\nmining to discover the meaning of\\nclusters in biological entities\\n\\n\\xa0\\n\\n\\xa0\\n\\n\\xa0\\n\\nClarissa David\\n\\nData Scientist\\nSão Bernardo do Campo, São Paulo, Brasil\\n\\nResumo\\nGraduada em Bacharelado em Ciência e Tecnologia e Bacharelado\\nem Ciência da Computação, ambos pela Universidade Federal\\ndo ABC (UFABC), a atividade que mais possuo afinidade é\\nobter diversos tipos de conhecimentos novos e colocá-los em\\nprática. Amo a profissão que estudei e gosto de aprender novas\\nlinguagens e testá-las, sendo a programação um dos meus hobbies\\nfavoritos. Estou em meu segundo ano de mestrado em Ciência\\nda Computação (término 07/2019), pela UFABC, e minha área\\nconcentra-se em Machine Learning, Data Mining e NLP.\\n\\nExperiência\\n\\nSemantix\\nData Scientist\\nfevereiro de 2019\\xa0-\\xa0Present\\xa0\\n\\nThales\\nDesenvolvedora Jr\\noutubro de 2018\\xa0-\\xa0janeiro de 2019\\xa0(4 meses)\\n\\nFreelance\\nConsultora\\nagosto de 2018\\xa0-\\xa0agosto de 2018\\xa0(1 mês)\\nConsultoria para análise estatística de dados psicológicos.\\n\\nFormação acadêmica\\nUniversidade Federal do ABC - UFABC\\nMestrado,\\xa0Ciência da Computação\\xa0·\\xa0(2017\\xa0-\\xa02019)\\n\\nUniversidade Federal do ABC - UFABC\\nBacharelado,\\xa0Ciência da Computação\\xa0·\\xa0(2012\\xa0-\\xa02018)\\n\\nPage 1 of 2\\n\\n\\x0c\\xa0\\n\\n\\xa0\\n\\n\\xa0\\n\\nUniversidade Federal do ABC - UFABC\\nBacharelado,\\xa0Ciência e Tecnologia\\xa0·\\xa0(2012\\xa0-\\xa02016)\\n\\nPage 2 of 2\\n\\n\\x0c'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile_in_txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o arquivo TXT carregado, vem a parte de criação das funções para a extração automática das informações. Para isto foi criado uma classe, para uma melhor organização e encapsulamento. As duas primeiras funções, remove_strange e no_break_line são funções de pré-processamento. Ineretemente a maior parte dos dados vem com \"lixos\" e caracters que não queremos e podemos descartar ou substituir, sendo necessário um pré-processamento dos dados. \n",
    "\n",
    "As funções seguintes são responsáveis pelas extrações das informações: getContatos é responsável por extrair as informações de contatos, getExperiencia é responsável por extrair informações de experiências profissionais anteriores, getFormacaoAcademica é responsável por extrair informações de formações acadêmicas, getIdiomas é responsável por extrair quais idiomas a pessoa domina e getResumo é responsável por extrair o resumo dado no currículo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "class ExtracaoInformacaoCV(object):\n",
    "    \n",
    "    def remove_strange(self, sentence):\n",
    "        sentence_sub = sentence.replace(u'\\x0c', u' ')\n",
    "        sentence_sub = sentence_sub.replace(\"Page 2 of 2\", \"\")\n",
    "        sentence_sub = sentence_sub.replace(\"Page 1 of 2\", \"\")\n",
    "        sentence_sub = sentence_sub.replace(\"·\", \" \")\n",
    "        sentence_sub = sentence_sub.replace(\" - \", \"-\")\n",
    "        sentence_sub = sentence_sub.replace(\" -\", \"-\")\n",
    "        sentence_sub = sentence_sub.replace(\"- \", \"-\")\n",
    "        sentence_sub = unicodedata.normalize(\"NFKD\", sentence_sub)\n",
    "        return sentence_sub\n",
    "\n",
    "    def no_break_line(self, file_to_be_clean):\n",
    "        split_break_line = re.compile('\\n \\n').split(file_to_be_clean)\n",
    "        clean_break_line = [re.sub(r'\\n', ' ', bl) for bl in split_break_line]\n",
    "    \n",
    "        return(clean_break_line)\n",
    "    \n",
    "    def getContatos(self, inputString):\n",
    "        cleaning_data = ''.join(no_break_line(inputString))\n",
    "        data = remove_strange(cleaning_data)\n",
    "        data_string = ''.join(no_break_line(data))\n",
    "        regex_contatos = r\"((http|https)\\:\\/\\/)?[a-zA-Z0-9\\.\\/\\?\\:@\\-_=#]+\\.([a-zA-Z]){2,6}([a-zA-Z0-9\\.\\&\\/\\?\\:@\\-_=#])*\"\n",
    "        lista_contato = []\n",
    "        for match in re.finditer(regex_contatos, data_string):\n",
    "            lista_contato.append(match.group(0))\n",
    "        if lista_contato != []:\n",
    "            return lista_contato\n",
    "        else:\n",
    "            return \"Contato não informado\"\n",
    "    \n",
    "    def getExperiencia(self, inputString):\n",
    "        data = remove_strange(inputString)\n",
    "        data = data.replace('\\n', 'ENTER')\n",
    "        match = re.search(r\"Experiência(.*?)\\.ENTERENTER\", data, re.IGNORECASE)\n",
    "        if match != None:\n",
    "            experiencia = match.group(1)\n",
    "        return experiencia.replace('ENTER', ' ').lstrip()\n",
    "    \n",
    "    def getFormacaoAcademica(self, inputString):\n",
    "        data = remove_strange(inputString)\n",
    "        data = data.replace('\\n', 'ENTER')\n",
    "        match = re.search(r\"Formação\\s*acadêmica(.*?)$\", data, re.IGNORECASE)\n",
    "        if match != None:\n",
    "            formacao_academica = match.group(1)\n",
    "        return formacao_academica.replace('ENTER', ' ').strip()\n",
    "    \n",
    "    def getIdiomas(self, inputString):\n",
    "        data = remove_strange(inputString)\n",
    "        data = data.replace('\\n', 'ENTER')\n",
    "        match = re.search(r\"Languages(.*?)ENTERENTER\", data, re.IGNORECASE)\n",
    "        if match != None:\n",
    "            idiomas = match.group(1)\n",
    "        return idiomas.replace('ENTER', ' ').lstrip()\n",
    "    \n",
    "    def getResumo(self, inputString):\n",
    "        data = remove_strange(profile_in_txt)\n",
    "        data = data.replace('\\n', 'ENTER')\n",
    "        match = re.search(r\"Resumo(.*?)ENTERENTER\", data, re.IGNORECASE)\n",
    "        if match != None:\n",
    "            resumo = match.group(1)\n",
    "        return resumo.replace('ENTER', ' ').strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com as funções feitas e a classe pronta, um objeto dela é instanciado e um dataframe é feito para poder guardar essas informações que serão extraídas, podendo posteriormente ser salvo em um banco de dados e consultado para aplicações futuras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "objeto_extracao = ExtracaoInformacaoCV()\n",
    "\n",
    "colunas = ['contatos', 'experiencia', 'formacao_academica', 'idiomas', 'resumo']\n",
    "df_resultado_extracao = pd.DataFrame(columns=colunas)\n",
    "lista_extracoes_resultantes = []\n",
    "lista_extracoes_resultantes.append(objeto_extracao.getContatos(profile_in_txt))\n",
    "lista_extracoes_resultantes.append(objeto_extracao.getExperiencia(profile_in_txt))\n",
    "lista_extracoes_resultantes.append(objeto_extracao.getFormacaoAcademica(profile_in_txt))\n",
    "lista_extracoes_resultantes.append(objeto_extracao.getIdiomas(profile_in_txt))\n",
    "lista_extracoes_resultantes.append(objeto_extracao.getResumo(profile_in_txt))\n",
    "df_resultado_extracao.loc[len(df_resultado_extracao), :] = lista_extracoes_resultantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultado\n",
    "\n",
    "A seguir temos o resultado da técnica de extração de informações do currículo. Com as funções de extrações obtêm-se um dataframe de resultado contendo os contatos, experiências profissionais, formação acadêmica, idiomas e o resumo, tudo que estava contido no currículo, mas de forma estruturada automaticamente. As técnicas utilizadas para extrações foram técnicas de expressões regulares e processamento de linguagem natural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contatos</th>\n",
       "      <th>experiencia</th>\n",
       "      <th>formacao_academica</th>\n",
       "      <th>idiomas</th>\n",
       "      <th>resumo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[www.linkedin.com/in/clarissa-david-a10824170, github.com/ClaDavid]</td>\n",
       "      <td>Semantix Data Scientist fevereiro de 2019 - Present   Thales Desenvolvedora Jr outubro de 2018 - janeiro de 2019 (4 meses)  Freelance Consultora agosto de 2018 - agosto de 2018 (1 mês) Consultoria para análise estatística de dados psicológicos</td>\n",
       "      <td>Universidade Federal do ABC-UFABC Mestrado, Ciência da Computação   (2017 - 2019)  Universidade Federal do ABC-UFABC Bacharelado, Ciência da Computação   (2012 - 2018)              Universidade Federal do ABC-UFABC Bacharelado, Ciência e Tecnologia   (2012 - 2016)</td>\n",
       "      <td>Espanhol (Limited Working) Inglês (Full Professional) Português brasileiro (Native or Bilingual)</td>\n",
       "      <td>Graduada em Bacharelado em Ciência e Tecnologia e Bacharelado em Ciência da Computação, ambos pela Universidade Federal do ABC (UFABC), a atividade que mais possuo afinidade é obter diversos tipos de conhecimentos novos e colocá-los em prática. Amo a profissão que estudei e gosto de aprender novas linguagens e testá-las, sendo a programação um dos meus hobbies favoritos. Estou em meu segundo ano de mestrado em Ciência da Computação (término 07/2019), pela UFABC, e minha área concentra-se em Machine Learning, Data Mining e NLP.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              contatos                                                                                                                                                                                                                                              experiencia                                                                                                                                                                                                                                                               formacao_academica                                                                                             idiomas  \\\n",
       "0  [www.linkedin.com/in/clarissa-david-a10824170, github.com/ClaDavid]  Semantix Data Scientist fevereiro de 2019 - Present   Thales Desenvolvedora Jr outubro de 2018 - janeiro de 2019 (4 meses)  Freelance Consultora agosto de 2018 - agosto de 2018 (1 mês) Consultoria para análise estatística de dados psicológicos  Universidade Federal do ABC-UFABC Mestrado, Ciência da Computação   (2017 - 2019)  Universidade Federal do ABC-UFABC Bacharelado, Ciência da Computação   (2012 - 2018)              Universidade Federal do ABC-UFABC Bacharelado, Ciência e Tecnologia   (2012 - 2016)  Espanhol (Limited Working) Inglês (Full Professional) Português brasileiro (Native or Bilingual)   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 resumo  \n",
       "0  Graduada em Bacharelado em Ciência e Tecnologia e Bacharelado em Ciência da Computação, ambos pela Universidade Federal do ABC (UFABC), a atividade que mais possuo afinidade é obter diversos tipos de conhecimentos novos e colocá-los em prática. Amo a profissão que estudei e gosto de aprender novas linguagens e testá-las, sendo a programação um dos meus hobbies favoritos. Estou em meu segundo ano de mestrado em Ciência da Computação (término 07/2019), pela UFABC, e minha área concentra-se em Machine Learning, Data Mining e NLP.  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "df_resultado_extracao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impact in the business\n",
    "\n",
    "As part of the dynamic of the homework, this subsection will be done in English. Automating the process of information extraction can not only optimize time, but also optimize recourse in the question of people, money and organization. Doing this manually or using natural language process can be susceptible to errors that can cost time and rework.\n",
    "\n",
    "With this feature, it will be easier to hire people that are more aligned with the company's goals, also making it easier to view information about who works for Uber, generating greater control and comfort for both drivers and passengers.\n",
    "\n",
    "In the future, this feature can also be a start to something bigger: people and talent analytics, in partnership with the databases that HR has, not only automating the extraction of information, but also improve the quality of all employees and users as a whole."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Códigos\n",
    "\n",
    "Os códigos também podem ser encontrados no github, no seguinte repositório: https://github.com/ClaDavid/UberCreativeExercise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
